{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabb8768-ce61-424c-86d2-886bafaf63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ed7e1b-9ba5-4004-a9fa-e8e673c467e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b2a08e7-8401-4506-ac8c-062ed7093ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in os.listdir(os.path.join('C:/Users/DELL/Pictures/Camera Roll/', 'positives')):\n",
    "#     img_filename = file\n",
    "#     img = cv2.imread(os.path.join('C:/Users/DELL/Pictures/Camera Roll/positives', img_filename))\n",
    "#     newpath = os.path.join('data', 'positives', img_filename)\n",
    "#     rescaled_img =  img[200:200+250, 250:250+250, :]\n",
    "#     cv2.imwrite(newpath, rescaled_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f511953-f876-4af0-b6b5-c126ebc8b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for directory in os.listdir('lfw'):\n",
    "#     for file in os.listdir(os.path.join('lfw', directory)):\n",
    "#         ex_path = os.path.join('lfw', directory, file)\n",
    "#         new_path = os.path.join('data', 'negatives', file)\n",
    "#         os.replace(ex_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdade3c-5cab-4335-a462-3c957c024ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files('data\\\\anchor\\\\*.jpg')\n",
    "positive = tf.data.Dataset.list_files('data\\\\positives\\\\*.jpg')\n",
    "negative = tf.data.Dataset.list_files('data\\\\negatives\\\\*.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef27087-b940-43dc-97e8-01e75733c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(file):\n",
    "    # read img and store it as byte string\n",
    "    byte_img = tf.io.read_file(file)\n",
    "    #convert to tensor representing image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    img = img/ 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833932a0-db9d-4dd4-b9e2-6ff65df8bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creats 1s and 0s labeL\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a4a861-66a9-4979-9872-ebd27e6dab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1098e2e-2449-4ce8-824f-6d103dc1c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f22a2fe-9222-48b0-8c11-de4798513027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess zipped data\n",
    "def preprocess_zipped(anchor, validation ,label):\n",
    "    return(preprocess_img(anchor), preprocess_img(validation), label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9df31eb-beb6-42d9-8498-5a2eee6c7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data = data.map(preprocess_zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8575ad08-f312-44d1-b4c1-1cb811395949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_data.cache()\n",
    "df = df.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b1cd381-0c20-4ac3-9c37-6d51f4738450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ShuffleDataset element_spec=(TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4bef0c3-2246-4e96-853c-2638889a3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e0bbe22-4dfa-468d-b66a-6d41a2f19918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.next()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed78ccc7-fc6d-497b-8ede-5a50e266da00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 286, 122)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(df) * 1), round(len(df) * 0.7), 408-286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78c40116-3b63-4b85-ae8d-0c30e74c2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.take(286)\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f31bda9-c8d0-4843-881e-27cfbcc9fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df.skip(286)\n",
    "test_data = test_data.take(122)\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08959a84-31a6-4197-98df-6b6b58776ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be1939-3c91-481f-9f40-bc14b6efb6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
